#!/usr/bin/env python
# coding: utf-8

# # Assignment 2- Lasso Regression and Inductive Conformal Prediction

# Importing diabetes dataset using the scikit-learn function load_version 

# In[530]:


from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
diabetes= load_diabetes()


# Splitting the dataset using train_test_split with the birthdate as the random_state

# In[531]:


Xtrain, Xtest, ytrain, ytest = train_test_split(diabetes.data, diabetes.target, random_state= 2206)
print(Xtrain.shape)
print(Xtest.shape)


# In[532]:


print(diabetes.DESCR)


# Importing the Lasso model from the Sklearn linear models and fitting to the training set

# In[533]:


import numpy as np
from sklearn.linear_model import Lasso
model= Lasso()
model.fit(Xtrain, ytrain)        


# Now, Calculating the R-squared for the training set which is 0.3353391586474068
# 

# In[534]:


model.score(Xtrain, ytrain)


# Calculating the R-squared for the test set. Here, as we can see, the model fits better for the test set with an accuracy of 0.36919646977018694.
# 

# In[535]:


model.score(Xtest, ytest)


# The accuracy for the training and test set is very low on the dataset from the scikit learning.

# Now, calculating the number of features used by the model with the default parameters. And we can see out of 10 features, only 2 have been used which is not good enough at all.

# In[536]:


np.sum(model.coef_!=0)


# Computing which 2 features are used by the model & their respective coefficients. And we can see that only bmi (body mass index) and s5(ltg, lamotrigine) have been used by the Lasso model with the coefficients as given below

# In[537]:


Feat= dict(zip(diabetes.feature_names, model.coef_))
Feat


# Now loading the original diabetes dataset using the 'np.genfromtxt' function from numpy

# In[538]:


import numpy as np
X= np.genfromtxt("diabetes.data", delimiter= "\t",skip_header=1, usecols=np.arange(10))

X[:3]


# In[539]:


y= np.genfromtxt("diabetes.data", delimiter= "\t", skip_header=1, usecols= 10, dtype= int)

y[:2]


# Splitting into train and test using train_test_split with the random state again as the birthdate

# In[540]:


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=2206)


# In[541]:


from sklearn.linear_model import Lasso
lasso= Lasso().fit(X_train, y_train)
lasso.score(X_train, y_train)


# In[542]:


lasso.score(X_test, y_test)


# In[543]:


np.sum(lasso.coef_!=0)


# Now, this is better than the previous accuracy scores. The training accuracy R-squared of 0.49384300753597477 & test accuracy R-squared as 0.553757135966294. With 9 features used out of 10, which has been an increase from the 2 we saw in the scikit learn dataset.
# 
# Out of 10, only s4 was not used at all. s4 is thyroid stimulating hormone

# In[544]:


Feat= dict(zip(diabetes.feature_names, lasso.coef_))
Feat


# Importing StandardScaler and preprocessing the dataset- by fitting it on the training set and transforming the test set.

# In[545]:


from sklearn.preprocessing import StandardScaler

scaler= StandardScaler()
scaler.fit(X_train)


# In[546]:


trainX_scaled= scaler.transform(X_train)
testX_scaled= scaler.transform(X_test)


# In[547]:


from sklearn.linear_model import Lasso
lasso= Lasso().fit(trainX_scaled, y_train)
lasso.score(trainX_scaled, y_train)


# In[548]:


lasso.score(testX_scaled, y_test)


# After using StandardScaler and transforming the train & test set, we obtain a training R-squared of 0.4967660417157793 & a test of 0.5504703582558883 which is quite similar to the one when we applied Lasso on the original dataset.
# 
# It is far away from the one from the scikit function diabetes data. And the reason for this might be as the dataset from scikit learning is normalized this is why it gives such a result in the Ex.7.
# 
# Also, after using StandardScaler we have seen that the number of features used has gone from 9 (from Exercise. 6) to 7 (this exercise). Below are the number of features used.

# In[549]:


Feat= dict(zip(diabetes.feature_names, lasso.coef_))
Feat


# Features not taken into the use are age, s2: low-density lipoproteins & s4: thyroid stimulating hormone

# In[550]:


np.sum(lasso.coef_!=0)


# Now we initiate a for loop to test the model for R-squared for test using different values of parameters. The parameters include: 0.1, 0.01, 1, 5, 10. 
# 
# It prints out the values for training and test R-squared both with respective values of alpha and having max iterations as 100000. It also stores the values of test R-squared in the TestModel

# In[551]:


model=[]
TestModel=[]

for A in [0.1, 0.01, 1, 5, 10]:
   
    lasso = Lasso(alpha= A, max_iter= 100000)
    lasso.fit(trainX_scaled, y_train)
    model= lasso.score(trainX_scaled, y_train)
    print("Training R Squared when alpha" + " " + str(A) + ":", model, "\n")
    modo= lasso.score(testX_scaled, y_test)
    TestModel.append(lasso.score(testX_scaled, y_test))
    
    print("Test R Squared when alpha" + " " + str(A) + ":", modo, "\n")
    print("----------------------------------------------------------------")


# Below, we operate a separate for loop for the Features used which iterates over the alphas which we want to test or vary on. Note: the default alpha for Lasso model is 1

# In[552]:


Features=[]
for A in [0.1, 0.01, 1, 5, 10]:
    
    lasso = Lasso(alpha= A)
    lasso.fit(trainX_scaled, y_train)
    lasso.score(testX_scaled, y_test)    
    Features.append(np.sum(lasso.coef_!=0))
   
Features


# As we can see from the above, as the alpha increases the test R-squared score descreases ie. our model is less accurate. At the same time, the test model for alpha: 0.1 & 0.01 is accurate as compared to. Also, the number of features used also decreases as the alpha has increased. We store the the features used in Features.

# Now, we plot the graph for the total features used vs the R-squared value of the test model and we get this curve. 

# In[553]:


import matplotlib.pyplot as plt

plt.plot(Features, TestModel, marker= 'o', color= 'red', label= 'R-Squared')
plt.xlabel("Features used")
plt.ylabel("R squared for test")
plt.legend(loc= 'best')


# We can observe from the graph that as the accuracy of the model increases, more number of features are in use. Therefore, for the alphas of 0.1 & 0.01, the accuracy is at the highest among others and number of feature used is also the same; there is not much difference between the two and hence we also see the their points on the graph kind of overlapping on each other. And the point on the curve (10, 0.5535) would be my preference.
# 

# Using GridSearchCV we choose the regularization parameter for the Lasso. We take the parameters as below & cv as 10 folds

# In[554]:


param_grid= { 'alpha':  [0.01, 0.1, 1, 5, 10, 100] }


# In[555]:


from sklearn.model_selection import GridSearchCV
grid_search= GridSearchCV(Lasso(), param_grid, cv= 10)


# In[556]:


grid_search.fit(trainX_scaled, y_train)


# In[557]:


grid_search.score(testX_scaled, y_test)


# In[558]:


print(grid_search.best_estimator_)


# As per the grid search CV, it selects the parameter as 1, so will take the Rsquared value for train and test using this value.
# 

# In[559]:


lasso = Lasso(alpha= 1)
lasso.fit(trainX_scaled, y_train)
lasso.score(trainX_scaled, y_train)


# In[560]:


lasso.score(testX_scaled, y_test)


# In[561]:


np.sum(lasso.coef_!=0)


# The R-squared for train is 0.4967660417157793  
# The test R-squared is 0.5504703582558883.
# 
# Also the number of features used are 7.

# In[ ]:





# # Inductive Conformal Prediction

# We will split the training set into two- Training set proper and Calibration Set (size of 99) and use my birthdate for the random state. Further, we will fit StandardScaler on the training set proper & transform all the three (Training set proper, Calibration set and the test set)

# In[ ]:





# In[ ]:





# In[562]:


XtrainProper, XtrainCalibration, ytrainProper, ytrainCalibration = train_test_split(X_train, y_train, test_size= 99, random_state= 2206)


# In[563]:


scaler.fit(XtrainProper)
XtrainProper_scaled =  scaler.transform(XtrainProper)


# In[564]:


XtrainCalibration_scaled =  scaler.transform(XtrainCaliberation)
Xtest_scaled =  scaler.transform(X_test)


# Now, we will fit the Lasso model on the Training set proper and use it to predict the scaled calibration set as yhat. 

# In[565]:


from sklearn.linear_model import Lasso
lasso =  Lasso().fit(XtrainProper_scaled, ytrainProper)
yhat =  lasso.predict(XtrainCalibration_scaled)


# Will take the absolute values of the subtraction of the ytrain calibration set and the yhat(predicted ytrain calibration)

# In[566]:


alpha = abs(np.subtract(ytrainCalibration, yhat))


# In[567]:


SortedAlphas= np.sort(alpha)


# We sort the alphas into ascending order now. 

# In[568]:


K05= [(1-0.05)*(99 + 1)]


# In[569]:


K05


# Calculated the K for the significance level 5% & it is 95. Now we will take the 94 value as K-1 measurement in C

# In[570]:


C05= SortedAlphas[94]
C05


# In[571]:


C05_length= 2*C05
C05_length


# The prediction interval for significance level 5% is 197.7731.

# Now for the significance level 20%

# In[572]:


K20= [(1-0.2)*(99+1)]
K20


# We will take K-1 measurement in C now ie. 79

# In[573]:


C20= SortedAlphas[79]
C20


# In[574]:


C20_length= 2* C20
C20_length


# The length of the prediction interval for the significance level 20% is 137.0988

# In[ ]:




